import torch
import torch.nn as nn
import torch.nn.functional as F
from pina.model import FeedForward, DeepONet
from pina.model.layers import FourierFeatureEmbedding
from pina.utils import LabelTensor


# ğŸ“Œ æ™‚é–“å­ç¶²è·¯
class TimeNet(nn.Module):
    def __init__(self, input_dim=1, hidden_dim=32, output_dim=16):
        super(TimeNet, self).__init__()
        self.fc1 = FeedForward(input_dimensions=input_dim, output_dimensions=output_dim, n_layers=2,inner_size=128)
        self.activation = nn.Tanh()

    def forward(self, t):
        """
        t: LabelTensor (batch_size, 1) ä¾†è‡ª 'f' é »ç‡ç¶­åº¦
        """
        t = self.activation(self.fc1(t))
        return t  # (batch_size, output_dim)


# ğŸ“Œ ç©ºé–“å­ç¶²è·¯
class SpaceNet(nn.Module):
    def __init__(self, input_dim=3, hidden_dim=64, output_dim=32):
        super(SpaceNet, self).__init__()
        self.fc1 = FeedForward(input_dimensions=input_dim, output_dimensions=hidden_dim, layers=[100])
        self.activation = nn.Tanh()
        self.fourierNet = MultiscaleFourierNet(hidden_dim,hidden_dim)
        self.fc2 = FeedForward(input_dimensions=hidden_dim, output_dimensions=output_dim, n_layers=10,inner_size=128)
    def forward(self, x):
        """
        x: LabelTensor (batch_size, 3) ä¾†è‡ª 'x', 'y', 'z' ç¶­åº¦
        """
        x = self.activation(self.fc1(x))
        x = self.activation(self.fourierNet(x))
        x = self.activation(self.fc2(x))
        return x  # (batch_size, output_dim)


# ğŸ“Œ èåˆå±¤
class FusionNet(nn.Module):
    def __init__(self, time_feature_dim=16, space_feature_dim=32, output_dim=32):
        super(FusionNet, self).__init__()
        self.fc1 = nn.Linear(time_feature_dim + space_feature_dim, 100)
        self.fc2 = nn.Linear(100, output_dim)
        self.activation = nn.Tanh()

    def forward(self, time_features, space_features):
        """
        time_features: æ™‚é–“ç‰¹å¾µ (batch_size, time_feature_dim)
        space_features: ç©ºé–“ç‰¹å¾µ (batch_size, space_feature_dim)
        """
        combined = torch.cat((time_features, space_features), dim=1)
        combined = self.activation(self.fc1(combined))
        output = self.activation(self.fc2(combined))
        return output  # (batch_size, output_dim)


# ğŸ“Œ ä¸»ç¶²è·¯ï¼šæ™‚é–“èˆ‡ç©ºé–“åˆ†é›¢è™•ç†
class TimeSpaceNet(nn.Module):
    def __init__(self):
        super(TimeSpaceNet, self).__init__()
        self.time_net = TimeNet(output_dim=8)
        self.space_net = SpaceNet(output_dim=64)
        self.fusion_net = FusionNet(time_feature_dim=8, space_feature_dim=64, output_dim=64)
        self.layers = FeedForward(input_dimensions=64, output_dimensions=2, n_layers=10,inner_size=128)
    def forward(self, input_tensor: LabelTensor):
        """
        input_tensor: LabelTensor æ¨™è¨˜ ['x', 'y', 'z', 'f']
        """
        # å¾ LabelTensor ä¸­æå–æ™‚é–“å’Œç©ºé–“ç¶­åº¦
        time_input = input_tensor.extract(['f'])/1e6  # æå–æ™‚é–“ç¶­åº¦
        space_input = input_tensor.extract(['x', 'y', 'z'])  # æå–ç©ºé–“ç¶­åº¦

        # åˆ†åˆ¥ç¶“éæ™‚é–“å’Œç©ºé–“å­ç¶²è·¯
        time_features = self.time_net(time_input)
        space_features = self.space_net(space_input)

        # èåˆæ™‚é–“èˆ‡ç©ºé–“ç‰¹å¾µ
        output = self.fusion_net(time_features, space_features)
        output = self.layers(output)
        return LabelTensor(output, labels=['phi_r', 'phi_i'])

class MultiscaleFourierNet(torch.nn.Module):
    def __init__(self,input_dim,output_dim):
        super().__init__()
        self.embedding1 = FourierFeatureEmbedding(input_dimension=input_dim,
                                                  output_dimension=100,
                                                  sigma=1)
        self.embedding2 = FourierFeatureEmbedding(input_dimension=input_dim,
                                                  output_dimension=100,
                                                  sigma=1)
        self.embedding3 = FourierFeatureEmbedding(input_dimension=input_dim,
                                                  output_dimension=100,
                                                  sigma=1e-2)
        self.final_layers = FeedForward(input_dimensions=300, output_dimensions=output_dim, n_layers=10,inner_size=128)


    def forward(self, x):
        e1 = self.embedding1(x)
        e2 = self.embedding2(x)
        e3 = self.embedding3(x)
        return self.final_layers(torch.cat([e1, e2, e3], dim=-1))


class DEEPONET(nn.Module):
    def __init__(self,input_dim=3,output_dim=2):
        super().__init__()
        branch_net1 = FeedForward(input_dimensions=input_dim, output_dimensions=100)
        trunk_net1 = FeedForward(input_dimensions=1, output_dimensions=100)
        self.deepONet1 = DeepONet(branch_net=branch_net1,
                     trunk_net=trunk_net1,
                     input_indeces_branch_net=['x', 'y', 'z'],
                     input_indeces_trunk_net=['f'],
                     reduction='+',
                     aggregator='*')
        branch_net2 = FeedForward(input_dimensions=input_dim, output_dimensions=100)
        trunk_net2 = FeedForward(input_dimensions=1, output_dimensions=100)
        self.deepONet2 = DeepONet(branch_net=branch_net2,
                     trunk_net=trunk_net2,
                     input_indeces_branch_net=['x', 'y', 'z'],
                     input_indeces_trunk_net=['f'],
                     reduction='+',
                     aggregator='*')

        self.final_layers = FeedForward(input_dimensions=2, output_dimensions=output_dim,
                                        layers=[100, 100])
    def forward(self, x):
        return self.final_layers(torch.cat([self.deepONet1(x),self.deepONet2],dim=-1))





class PointNetSegmentation(nn.Module):
    def __init__(self, input_dim=3, output_dim=4):
        """
        PointNet ç”¨æ–¼é€é»ç‰¹å¾µæå–æˆ–åˆ†å‰²
        :param input_dim: æ¯å€‹é»çš„ç‰¹å¾µç¶­åº¦ (é è¨­4: x, y, z, f)
        :param output_dim: æ¯å€‹é»çš„è¼¸å‡ºç‰¹å¾µç¶­åº¦
        """
        super(PointNetSegmentation, self).__init__()

        # **1ï¸âƒ£ å±€éƒ¨ç‰¹å¾µæå–**
        self.mlp1 = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU()
        )
        self.mlp2 = nn.Sequential(
            nn.Linear(64, 128),
            nn.ReLU()
        )
        self.mlp3 = nn.Sequential(
            nn.Linear(128, 256),
            nn.ReLU()
        )

        # **2ï¸âƒ£ å…¨å±€ç‰¹å¾µæå–**
        self.global_mlp = nn.Sequential(
            nn.Linear(256, 512),
            nn.ReLU()
        )
        self.global_max_pool = nn.AdaptiveMaxPool1d(1)

        # **3ï¸âƒ£ ç‰¹å¾µèåˆ**
        self.fusion_mlp1 = nn.Sequential(
            nn.Linear(256 + 512, 256),
            nn.ReLU()
        )
        self.fusion_mlp2 = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU()
        )

        # **4ï¸âƒ£ è¼¸å‡ºå±¤**
        self.output_mlp = nn.Linear(128, output_dim)

    def forward(self, x):
        """
        å‰å‘å‚³æ’­
        :param x: é»é›²æ•¸æ“šï¼Œå½¢ç‹€ç‚º (batch_size, num_points, input_dim)
        :return: æ¯å€‹é»çš„ç‰¹å¾µè¼¸å‡ºï¼Œå½¢ç‹€ç‚º (batch_size, num_points, output_dim)
        """
        num_points, dimensions = x.shape

        # **Step 1: å±€éƒ¨ç‰¹å¾µæå–**
        x = x.view(-1, x.shape[-1])  # å±•å¹³ç‚º (batch_size * num_points, input_dim)
        x = self.mlp1(x)
        x = self.mlp2(x)
        x = self.mlp3(x)

        # é‚„åŸå½¢ç‹€
        x = x.view(1, num_points, -1)  # (batch_size, num_points, 256)
        point_features = x

        # **Step 2: å…¨å±€ç‰¹å¾µæå–**
        global_features = x.permute(0, 2, 1)  # (batch_size, 256, num_points)
        global_features = self.global_max_pool(global_features)  # (batch_size, 256, 1)
        global_features = global_features.reshape([1,-1])  # (batch_size, 256)
        global_features = self.global_mlp(global_features)  # (batch_size, 512)
        global_features = global_features.unsqueeze(1).repeat(1, num_points, 1)  # (batch_size, num_points, 512)

        # **Step 3: ç‰¹å¾µèåˆ**
        fusion_features = torch.cat([point_features, global_features], dim=2)  # (batch_size, num_points, 768)
        fusion_features = self.fusion_mlp1(fusion_features.view(-1, 256 + 512))
        fusion_features = self.fusion_mlp2(fusion_features)

        # é‚„åŸå½¢ç‹€
        fusion_features = fusion_features.view(1, num_points, -1)

        # **Step 4: è¼¸å‡ºæ¯å€‹é»çš„ç‰¹å¾µ**
        output = self.output_mlp(fusion_features)  # (batch_size, num_points, output_dim)

        return output.reshape([num_points,-1])


# æ¸¬è©¦ç¶²çµ¡
if __name__ == "__main__":
    # æ¸¬è©¦æ¨¡å‹
    batch_size = 16
    num_points = 1024
    input_dim = 4  # x, y, z, f
    output_dim = 4  # æ¯å€‹é»è¼¸å‡ºçš„ç‰¹å¾µç¶­åº¦

    # æ¨¡æ“¬é»é›²æ•¸æ“š
    point_cloud = torch.rand(num_points, input_dim)  # éš¨æ©Ÿé»é›²

    # åˆå§‹åŒ– PointNet
    model = PointNetSegmentation(input_dim=input_dim, output_dim=output_dim)

    # å‰å‘å‚³æ’­
    output = model(point_cloud)

    print("è¼¸å…¥å½¢ç‹€:", point_cloud.shape)  # (16, 1024, 4)
    print("è¼¸å‡ºå½¢ç‹€:", output.shape)  # (16, 1024, 4)



